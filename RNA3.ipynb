{"cells":[{"cell_type":"code","execution_count":1,"id":"606f6da8-a05b-49df-828e-dbfce740c011","metadata":{"id":"606f6da8-a05b-49df-828e-dbfce740c011","executionInfo":{"status":"ok","timestamp":1769606684704,"user_tz":-180,"elapsed":1601,"user":{"displayName":"Joharisoa Rakotoarison","userId":"07141762020706239303"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":2,"id":"ceecc4cc-0ff3-4460-9fc8-117a30490f65","metadata":{"id":"ceecc4cc-0ff3-4460-9fc8-117a30490f65","executionInfo":{"status":"ok","timestamp":1769606685082,"user_tz":-180,"elapsed":368,"user":{"displayName":"Joharisoa Rakotoarison","userId":"07141762020706239303"}}},"outputs":[],"source":["class artificial_neuron:\n","    def __init__(self, X_train, y_train, X_test, y_test):\n","        self.X_train = X_train\n","        self.y_train = y_train\n","        self.X_test = X_test\n","        self.y_test = y_test\n","\n","    def initialisation(self, n0, n1, n2):\n","        w1 = np.random.randn(n1, n0)\n","        b1 = np.random.randn(n1, 1)\n","        w2 = np.random.randn(n2, n1)\n","        b2 = np.random.randn(n2, 1)\n","\n","        parameters = {\n","            'w1': w1,\n","            'b1': b1,\n","            'w2': w2,\n","            'b2': b2\n","        }\n","        return parameters\n","\n","    def model(self, X, parameters):\n","        w1 = parameters['w1']\n","        b1 = parameters['b1']\n","        w2 = parameters['w2']\n","        b2 = parameters['b2']\n","\n","        # Forward propagation\n","        z1 = w1.dot(X.T) + b1\n","        A1 = 1 / (1 + np.exp(-z1))\n","        z2 = w2.dot(A1) + b2\n","        A2 = 1 / (1 + np.exp(-z2))\n","\n","        activations = {\n","            'A1': A1,\n","            'A2': A2,\n","        }\n","\n","        return activations\n","\n","    def log_loss(self, A, y):\n","        ep = 1e-15\n","        A = np.clip(A, ep, 1 - ep)  # Avoid log(0)\n","        return np.mean(-y * np.log(A) - (1 - y) * np.log(1 - A))\n","\n","    def back_propagation(self, X, y, activations, parameters):\n","        A1 = activations['A1']\n","        A2 = activations['A2']\n","        w2 = parameters['w2']\n","        m = y.shape[0]\n","\n","        # check if y is properly shaped for matrix operations\n","        y_reshaped = y.reshape(1, -1)\n","\n","        # Backpropagation for output layer\n","        dz2 = A2 - y_reshaped\n","        dw2 = (1/m) * dz2.dot(A1.T)\n","        db2 = (1/m) * np.sum(dz2, axis=1, keepdims=True)\n","\n","        # Backpropagation for hidden layer\n","        dz1 = w2.T.dot(dz2) * A1 * (1 - A1)\n","        dw1 = (1/m) * dz1.dot(X)\n","        db1 = (1/m) * np.sum(dz1, axis=1, keepdims=True)\n","\n","        gradients = {\n","            'dw1': dw1,\n","            'db1': db1,\n","            'dw2': dw2,\n","            'db2': db2,\n","        }\n","        return gradients\n","\n","    def update(self, parameters, gradients, learning_rate):\n","        w1 = parameters['w1']\n","        b1 = parameters['b1']\n","        w2 = parameters['w2']\n","        b2 = parameters['b2']\n","\n","        dw1 = gradients['dw1']\n","        db1 = gradients['db1']\n","        dw2 = gradients['dw2']\n","        db2 = gradients['db2']\n","\n","        w1 = w1 - learning_rate * dw1\n","        b1 = b1 - learning_rate * db1\n","        w2 = w2 - learning_rate * dw2\n","        b2 = b2 - learning_rate * db2\n","\n","        parameters = {\n","            'w1': w1,\n","            'b1': b1,\n","            'w2': w2,\n","            'b2': b2\n","        }\n","        return parameters\n","\n","    def predict(self, X, parameters):\n","        activations = self.model(X, parameters)\n","        A2 = activations['A2']\n","        return (A2 >= 0.5).astype(int)\n","\n","    def ARN(self, n1=120, learning_rate=0.01, n_iter=1000):\n","\n","        # Get dimensions\n","        n0 = self.X_train.shape[1]\n","        n2 = 1\n","\n","        # Initialize parameters\n","        parameters = self.initialisation(n0, n1, n2)\n","\n","        train_loss = []\n","        train_acc = []\n","        test_loss = []\n","        test_acc = []\n","\n","        # Training loop\n","        for i in tqdm(range(n_iter)):\n","\n","            # Forward propagation on training data\n","            activations_train = self.model(self.X_train, parameters)\n","            A2_train = activations_train['A2']\n","\n","            # Calculate metrics every 100 iterations\n","            if i % 100 == 0:\n","                # Train\n","                train_loss.append(self.log_loss(A2_train.T, self.y_train))\n","                y_pred_train = self.predict(self.X_train, parameters)\n","                train_acc.append(accuracy_score(self.y_train, y_pred_train.T))\n","\n","                # Test\n","                activations_test = self.model(self.X_test, parameters)\n","                A2_test = activations_test['A2']\n","                test_loss.append(self.log_loss(A2_test.T, self.y_test))\n","                y_pred_test = self.predict(self.X_test, parameters)\n","                test_acc.append(accuracy_score(self.y_test, y_pred_test.T))\n","\n","            # Backward propagation and update\n","            gradients = self.back_propagation(self.X_train, self.y_train, activations_train, parameters)\n","            parameters = self.update(parameters, gradients, learning_rate)\n","\n","        # Plot results\n","        plt.figure(figsize=(14, 6))\n","\n","        plt.subplot(1, 2, 1)\n","        plt.plot(train_loss, label='Train Loss')\n","        plt.plot(test_loss, label='Test Loss')\n","        plt.xlabel('Iterations (x100)')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","        plt.title('Training and Test Loss')\n","\n","        plt.subplot(1, 2, 2)\n","        plt.plot(train_acc, label='Train Accuracy')\n","        plt.plot(test_acc, label='Test Accuracy')\n","        plt.xlabel('Iterations (x100)')\n","        plt.ylabel('Accuracy')\n","        plt.legend()\n","        plt.title('Training and Test Accuracy')\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n","        return parameters\n","\n","    def get_weights(self, parameters):\n","        return parameters['w1'], parameters['w2']\n","\n","    def get_biases(self, parameters):\n","        return parameters['b1'], parameters['b2']"]},{"cell_type":"code","execution_count":null,"id":"5c610e33-f514-468c-a158-6e47ac14e5d6","metadata":{"id":"5c610e33-f514-468c-a158-6e47ac14e5d6"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}